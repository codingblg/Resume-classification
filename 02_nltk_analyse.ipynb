{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with the Resume Text and LinearSVC in scikit-learn \n",
    "\n",
    "## Agenda\n",
    "### Working with resume data\n",
    "<ul>\n",
    "    <li>read data from csv file</li>\n",
    "    <li>lemmatize and transform data</li>\n",
    "    <li>split and vectorize data</li>\n",
    "</ul>\n",
    "\n",
    "### LinearSVC classification\n",
    "<ul>\n",
    "    <li>Building a LinearSVC model</li>\n",
    "    <li>Comparing LinearSVC with logistic regression</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from result.csv\n",
    "import pandas as pd\n",
    "result = pd.read_csv('c:/python/result.csv')\n",
    "\n",
    "# print random sample to check the format\n",
    "result.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# define lemma, and stopword\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = set(stopwords.words('english'))\n",
    "\n",
    "# lemmatizer and remove stopword\n",
    "result['clean'] = result['description'].apply(lambda x: \" \".join([lemmatizer.lemmatize(i) for i in x.split() if i not in words]).lower())\n",
    "\n",
    "# remove the confuse titles. i.e. both 'Data Scientist' and 'Data Analyst' in title\n",
    "result['title_c'] = result['title'].map(lambda x: 1 if 'Data Scientist' in x and 'Data Analyst' in x else 0)\n",
    "result.drop(result[result.title_c == 1].index, inplace = True)\n",
    "\n",
    "# define 'Data Scientist' as 1 'Data Analyst' as 0\n",
    "result['title_c'] = result['title'].map(lambda x: 1 if 'Data Scientist' in x else 0)\n",
    "\n",
    "# print random sample to check the format\n",
    "result.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocess and fitting module from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # feature_extraction\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB # navie_bayes\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression # logisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC # SVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# build a pipeline\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer(stop_words = 'english', ngram_range=(1, 2))),\n",
    "                     ('clf',LinearSVC())\n",
    "                    ])\n",
    "\n",
    "# split (x,y) get train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(result['clean'], result.title_c, test_size=0.2, random_state=1)\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform LinearSVC and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict y_pred from X_test using the training result\n",
    "y_pred_class = text_clf.predict(X_test)\n",
    "\n",
    "# print classification_report\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print confusion_matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get feature names for SVM fitting\n",
    "X_train_tokens = text_clf.named_steps['vect'].get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dict to store feature and related importance\n",
    "feature = {}\n",
    "import matplotlib.pyplot as plt\n",
    "# plot top related features for svm\n",
    "import numpy as np\n",
    "# define function to plot features\n",
    "def plot_coefficients(classifier, feature_names, top_features=25):\n",
    "    # get the coef paratmeter and store to coef\n",
    "    coef = classifier.coef_.ravel()\n",
    "    # return the index of top positive and negative paratmeter\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors =['red' if c<0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2*top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1+2*top_features), feature_names[top_coefficients],rotation=60, ha='right')\n",
    "    plt.show()\n",
    "    # store top correlated parameter to feature.\n",
    "    for i in top_coefficients[:25]:\n",
    "        feature[feature_names[i]] = -coef[i]\n",
    "        \n",
    "cv = text_clf.named_steps['vect']\n",
    "svm = text_clf.named_steps['clf']\n",
    "plot_coefficients(svm, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a cloudword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline\n",
    "wordcloud = WordCloud(width=800, height=500)\n",
    "\n",
    "    \n",
    "wordcloud.generate_from_frequencies(frequencies=feature)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
